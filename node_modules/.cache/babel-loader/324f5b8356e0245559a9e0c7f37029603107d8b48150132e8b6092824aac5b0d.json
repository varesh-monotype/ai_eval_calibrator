{"ast":null,"code":"var _jsxFileName = \"/Users/tuliv/Documents/prompt_manual_eval/src/components/ScoreSummary.js\",\n  _s = $RefreshSig$();\nimport React, { useState, useEffect } from 'react';\nimport { getFontScores } from '../services/api';\nimport { jsxDEV as _jsxDEV } from \"react/jsx-dev-runtime\";\nconst ScoreSummary = ({\n  scores,\n  totalResults = 0,\n  currentPrompt = '',\n  refreshTrigger = 0\n}) => {\n  _s();\n  const [allScores, setAllScores] = useState([]);\n\n  // Load existing feedback on mount and when refresh is triggered\n  useEffect(() => {\n    const loadExistingFeedback = async () => {\n      try {\n        const existingScores = await getFontScores();\n        setAllScores(existingScores);\n      } catch (error) {\n        console.error('Error loading existing feedback:', error);\n      }\n    };\n    loadExistingFeedback();\n  }, [currentPrompt, refreshTrigger]); // Re-load when prompt changes or refresh is triggered\n\n  // Filter existing scores for current prompt only\n  const currentPromptScores = currentPrompt ? allScores.filter(score => score.promptName === currentPrompt) : [];\n\n  // For real-time updates, prioritize current session scores\n  // If we have current session scores, use those. Otherwise, use existing scores from JSON\n  const scoresToUse = scores.length > 0 ? scores : currentPromptScores;\n\n  // Debug logging to see what's happening\n  console.log('ScoreSummary render:', {\n    scoresLength: scores.length,\n    scoresToUseLength: scoresToUse.length,\n    currentPrompt,\n    refreshTrigger\n  });\n\n  // Helper function to normalize score format\n  const normalizeScore = score => {\n    if (typeof score === 'string') {\n      if (score === 'good' || score === 'Good Match') return 'Good Match';\n      if (score === 'average' || score === 'Average Match') return 'Average Match';\n      if (score === 'bad' || score === 'Bad Match') return 'Bad Match';\n    }\n    return score;\n  };\n  const goodScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Good Match').length;\n  const averageScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Average Match').length;\n  const badScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Bad Match').length;\n  const totalScores = scoresToUse.length;\n  const goodPercentage = totalScores > 0 ? Math.round(goodScores / totalScores * 100) : 0;\n  const averagePercentage = totalScores > 0 ? Math.round(averageScores / totalScores * 100) : 0;\n  const badPercentage = totalScores > 0 ? Math.round(badScores / totalScores * 100) : 0;\n  return /*#__PURE__*/_jsxDEV(\"div\", {\n    className: \"bg-white rounded-lg p-4 sm:p-6 shadow-sm\",\n    children: /*#__PURE__*/_jsxDEV(\"div\", {\n      className: \"space-y-3 sm:space-y-4\",\n      children: [/*#__PURE__*/_jsxDEV(\"div\", {\n        children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n          className: \"font-bold text-black mb-1 sm:mb-2 text-sm sm:text-base\",\n          children: \"Overall Progress:\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 60,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"p\", {\n          className: \"text-gray-600 text-xs sm:text-sm\",\n          children: [totalScores, \"/\", totalResults, \" results evaluated (\", totalResults > 0 ? Math.round(totalScores / totalResults * 100) : 0, \"%)\"]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 61,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 59,\n        columnNumber: 17\n      }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n        children: [/*#__PURE__*/_jsxDEV(\"h3\", {\n          className: \"font-bold text-black mb-2 sm:mb-3 text-sm sm:text-base\",\n          children: \"Score Distribution:\"\n        }, void 0, false, {\n          fileName: _jsxFileName,\n          lineNumber: 66,\n          columnNumber: 21\n        }, this), /*#__PURE__*/_jsxDEV(\"div\", {\n          className: \"flex flex-wrap gap-2 sm:gap-3\",\n          children: [/*#__PURE__*/_jsxDEV(\"span\", {\n            className: \"bg-green-600 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\",\n            children: [\"Good: \", goodPercentage, \"%\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 68,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n            className: \"bg-orange-500 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\",\n            children: [\"Average: \", averagePercentage, \"%\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 71,\n            columnNumber: 25\n          }, this), /*#__PURE__*/_jsxDEV(\"span\", {\n            className: \"bg-red-500 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\",\n            children: [\"Bad: \", badPercentage, \"%\"]\n          }, void 0, true, {\n            fileName: _jsxFileName,\n            lineNumber: 74,\n            columnNumber: 25\n          }, this)]\n        }, void 0, true, {\n          fileName: _jsxFileName,\n          lineNumber: 67,\n          columnNumber: 21\n        }, this)]\n      }, void 0, true, {\n        fileName: _jsxFileName,\n        lineNumber: 65,\n        columnNumber: 17\n      }, this)]\n    }, void 0, true, {\n      fileName: _jsxFileName,\n      lineNumber: 57,\n      columnNumber: 13\n    }, this)\n  }, void 0, false, {\n    fileName: _jsxFileName,\n    lineNumber: 56,\n    columnNumber: 9\n  }, this);\n};\n_s(ScoreSummary, \"IQxR8jsVAvWLMrghq86yjMfDluM=\");\n_c = ScoreSummary;\nexport default ScoreSummary;\nvar _c;\n$RefreshReg$(_c, \"ScoreSummary\");","map":{"version":3,"names":["React","useState","useEffect","getFontScores","jsxDEV","_jsxDEV","ScoreSummary","scores","totalResults","currentPrompt","refreshTrigger","_s","allScores","setAllScores","loadExistingFeedback","existingScores","error","console","currentPromptScores","filter","score","promptName","scoresToUse","length","log","scoresLength","scoresToUseLength","normalizeScore","goodScores","s","averageScores","badScores","totalScores","goodPercentage","Math","round","averagePercentage","badPercentage","className","children","fileName","_jsxFileName","lineNumber","columnNumber","_c","$RefreshReg$"],"sources":["/Users/tuliv/Documents/prompt_manual_eval/src/components/ScoreSummary.js"],"sourcesContent":["import React, { useState, useEffect } from 'react';\nimport { getFontScores } from '../services/api';\n\nconst ScoreSummary = ({ scores, totalResults = 0, currentPrompt = '', refreshTrigger = 0 }) => {\n    const [allScores, setAllScores] = useState([]);\n\n    // Load existing feedback on mount and when refresh is triggered\n    useEffect(() => {\n        const loadExistingFeedback = async () => {\n            try {\n                const existingScores = await getFontScores();\n                setAllScores(existingScores);\n            } catch (error) {\n                console.error('Error loading existing feedback:', error);\n            }\n        };\n\n        loadExistingFeedback();\n    }, [currentPrompt, refreshTrigger]); // Re-load when prompt changes or refresh is triggered\n\n    // Filter existing scores for current prompt only\n    const currentPromptScores = currentPrompt ? allScores.filter(score => score.promptName === currentPrompt) : [];\n\n    // For real-time updates, prioritize current session scores\n    // If we have current session scores, use those. Otherwise, use existing scores from JSON\n    const scoresToUse = scores.length > 0 ? scores : currentPromptScores;\n\n    // Debug logging to see what's happening\n    console.log('ScoreSummary render:', {\n        scoresLength: scores.length,\n        scoresToUseLength: scoresToUse.length,\n        currentPrompt,\n        refreshTrigger\n    });\n\n    // Helper function to normalize score format\n    const normalizeScore = (score) => {\n        if (typeof score === 'string') {\n            if (score === 'good' || score === 'Good Match') return 'Good Match';\n            if (score === 'average' || score === 'Average Match') return 'Average Match';\n            if (score === 'bad' || score === 'Bad Match') return 'Bad Match';\n        }\n        return score;\n    };\n\n    const goodScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Good Match').length;\n    const averageScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Average Match').length;\n    const badScores = scoresToUse.filter(s => normalizeScore(s.score) === 'Bad Match').length;\n    const totalScores = scoresToUse.length;\n\n    const goodPercentage = totalScores > 0 ? Math.round((goodScores / totalScores) * 100) : 0;\n    const averagePercentage = totalScores > 0 ? Math.round((averageScores / totalScores) * 100) : 0;\n    const badPercentage = totalScores > 0 ? Math.round((badScores / totalScores) * 100) : 0;\n\n    return (\n        <div className=\"bg-white rounded-lg p-4 sm:p-6 shadow-sm\">\n            <div className=\"space-y-3 sm:space-y-4\">\n                {/* Overall Progress */}\n                <div>\n                    <h3 className=\"font-bold text-black mb-1 sm:mb-2 text-sm sm:text-base\">Overall Progress:</h3>\n                    <p className=\"text-gray-600 text-xs sm:text-sm\">{totalScores}/{totalResults} results evaluated ({totalResults > 0 ? Math.round((totalScores / totalResults) * 100) : 0}%)</p>\n                </div>\n\n                {/* Score Distribution */}\n                <div>\n                    <h3 className=\"font-bold text-black mb-2 sm:mb-3 text-sm sm:text-base\">Score Distribution:</h3>\n                    <div className=\"flex flex-wrap gap-2 sm:gap-3\">\n                        <span className=\"bg-green-600 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\">\n                            Good: {goodPercentage}%\n                        </span>\n                        <span className=\"bg-orange-500 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\">\n                            Average: {averagePercentage}%\n                        </span>\n                        <span className=\"bg-red-500 text-white px-2 sm:px-3 py-1 rounded-full text-xs sm:text-sm font-medium\">\n                            Bad: {badPercentage}%\n                        </span>\n                    </div>\n                </div>\n            </div>\n        </div>\n    );\n};\n\nexport default ScoreSummary; "],"mappings":";;AAAA,OAAOA,KAAK,IAAIC,QAAQ,EAAEC,SAAS,QAAQ,OAAO;AAClD,SAASC,aAAa,QAAQ,iBAAiB;AAAC,SAAAC,MAAA,IAAAC,OAAA;AAEhD,MAAMC,YAAY,GAAGA,CAAC;EAAEC,MAAM;EAAEC,YAAY,GAAG,CAAC;EAAEC,aAAa,GAAG,EAAE;EAAEC,cAAc,GAAG;AAAE,CAAC,KAAK;EAAAC,EAAA;EAC3F,MAAM,CAACC,SAAS,EAAEC,YAAY,CAAC,GAAGZ,QAAQ,CAAC,EAAE,CAAC;;EAE9C;EACAC,SAAS,CAAC,MAAM;IACZ,MAAMY,oBAAoB,GAAG,MAAAA,CAAA,KAAY;MACrC,IAAI;QACA,MAAMC,cAAc,GAAG,MAAMZ,aAAa,CAAC,CAAC;QAC5CU,YAAY,CAACE,cAAc,CAAC;MAChC,CAAC,CAAC,OAAOC,KAAK,EAAE;QACZC,OAAO,CAACD,KAAK,CAAC,kCAAkC,EAAEA,KAAK,CAAC;MAC5D;IACJ,CAAC;IAEDF,oBAAoB,CAAC,CAAC;EAC1B,CAAC,EAAE,CAACL,aAAa,EAAEC,cAAc,CAAC,CAAC,CAAC,CAAC;;EAErC;EACA,MAAMQ,mBAAmB,GAAGT,aAAa,GAAGG,SAAS,CAACO,MAAM,CAACC,KAAK,IAAIA,KAAK,CAACC,UAAU,KAAKZ,aAAa,CAAC,GAAG,EAAE;;EAE9G;EACA;EACA,MAAMa,WAAW,GAAGf,MAAM,CAACgB,MAAM,GAAG,CAAC,GAAGhB,MAAM,GAAGW,mBAAmB;;EAEpE;EACAD,OAAO,CAACO,GAAG,CAAC,sBAAsB,EAAE;IAChCC,YAAY,EAAElB,MAAM,CAACgB,MAAM;IAC3BG,iBAAiB,EAAEJ,WAAW,CAACC,MAAM;IACrCd,aAAa;IACbC;EACJ,CAAC,CAAC;;EAEF;EACA,MAAMiB,cAAc,GAAIP,KAAK,IAAK;IAC9B,IAAI,OAAOA,KAAK,KAAK,QAAQ,EAAE;MAC3B,IAAIA,KAAK,KAAK,MAAM,IAAIA,KAAK,KAAK,YAAY,EAAE,OAAO,YAAY;MACnE,IAAIA,KAAK,KAAK,SAAS,IAAIA,KAAK,KAAK,eAAe,EAAE,OAAO,eAAe;MAC5E,IAAIA,KAAK,KAAK,KAAK,IAAIA,KAAK,KAAK,WAAW,EAAE,OAAO,WAAW;IACpE;IACA,OAAOA,KAAK;EAChB,CAAC;EAED,MAAMQ,UAAU,GAAGN,WAAW,CAACH,MAAM,CAACU,CAAC,IAAIF,cAAc,CAACE,CAAC,CAACT,KAAK,CAAC,KAAK,YAAY,CAAC,CAACG,MAAM;EAC3F,MAAMO,aAAa,GAAGR,WAAW,CAACH,MAAM,CAACU,CAAC,IAAIF,cAAc,CAACE,CAAC,CAACT,KAAK,CAAC,KAAK,eAAe,CAAC,CAACG,MAAM;EACjG,MAAMQ,SAAS,GAAGT,WAAW,CAACH,MAAM,CAACU,CAAC,IAAIF,cAAc,CAACE,CAAC,CAACT,KAAK,CAAC,KAAK,WAAW,CAAC,CAACG,MAAM;EACzF,MAAMS,WAAW,GAAGV,WAAW,CAACC,MAAM;EAEtC,MAAMU,cAAc,GAAGD,WAAW,GAAG,CAAC,GAAGE,IAAI,CAACC,KAAK,CAAEP,UAAU,GAAGI,WAAW,GAAI,GAAG,CAAC,GAAG,CAAC;EACzF,MAAMI,iBAAiB,GAAGJ,WAAW,GAAG,CAAC,GAAGE,IAAI,CAACC,KAAK,CAAEL,aAAa,GAAGE,WAAW,GAAI,GAAG,CAAC,GAAG,CAAC;EAC/F,MAAMK,aAAa,GAAGL,WAAW,GAAG,CAAC,GAAGE,IAAI,CAACC,KAAK,CAAEJ,SAAS,GAAGC,WAAW,GAAI,GAAG,CAAC,GAAG,CAAC;EAEvF,oBACI3B,OAAA;IAAKiC,SAAS,EAAC,0CAA0C;IAAAC,QAAA,eACrDlC,OAAA;MAAKiC,SAAS,EAAC,wBAAwB;MAAAC,QAAA,gBAEnClC,OAAA;QAAAkC,QAAA,gBACIlC,OAAA;UAAIiC,SAAS,EAAC,wDAAwD;UAAAC,QAAA,EAAC;QAAiB;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC7FtC,OAAA;UAAGiC,SAAS,EAAC,kCAAkC;UAAAC,QAAA,GAAEP,WAAW,EAAC,GAAC,EAACxB,YAAY,EAAC,sBAAoB,EAACA,YAAY,GAAG,CAAC,GAAG0B,IAAI,CAACC,KAAK,CAAEH,WAAW,GAAGxB,YAAY,GAAI,GAAG,CAAC,GAAG,CAAC,EAAC,IAAE;QAAA;UAAAgC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAG,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OAC5K,CAAC,eAGNtC,OAAA;QAAAkC,QAAA,gBACIlC,OAAA;UAAIiC,SAAS,EAAC,wDAAwD;UAAAC,QAAA,EAAC;QAAmB;UAAAC,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OAAI,CAAC,eAC/FtC,OAAA;UAAKiC,SAAS,EAAC,+BAA+B;UAAAC,QAAA,gBAC1ClC,OAAA;YAAMiC,SAAS,EAAC,uFAAuF;YAAAC,QAAA,GAAC,QAC9F,EAACN,cAAc,EAAC,GAC1B;UAAA;YAAAO,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC,eACPtC,OAAA;YAAMiC,SAAS,EAAC,wFAAwF;YAAAC,QAAA,GAAC,WAC5F,EAACH,iBAAiB,EAAC,GAChC;UAAA;YAAAI,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC,eACPtC,OAAA;YAAMiC,SAAS,EAAC,qFAAqF;YAAAC,QAAA,GAAC,OAC7F,EAACF,aAAa,EAAC,GACxB;UAAA;YAAAG,QAAA,EAAAC,YAAA;YAAAC,UAAA;YAAAC,YAAA;UAAA,OAAM,CAAC;QAAA;UAAAH,QAAA,EAAAC,YAAA;UAAAC,UAAA;UAAAC,YAAA;QAAA,OACN,CAAC;MAAA;QAAAH,QAAA,EAAAC,YAAA;QAAAC,UAAA;QAAAC,YAAA;MAAA,OACL,CAAC;IAAA;MAAAH,QAAA,EAAAC,YAAA;MAAAC,UAAA;MAAAC,YAAA;IAAA,OACL;EAAC;IAAAH,QAAA,EAAAC,YAAA;IAAAC,UAAA;IAAAC,YAAA;EAAA,OACL,CAAC;AAEd,CAAC;AAAChC,EAAA,CA9EIL,YAAY;AAAAsC,EAAA,GAAZtC,YAAY;AAgFlB,eAAeA,YAAY;AAAC,IAAAsC,EAAA;AAAAC,YAAA,CAAAD,EAAA","ignoreList":[]},"metadata":{},"sourceType":"module","externalDependencies":[]}